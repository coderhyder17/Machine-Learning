{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "Ridge regression is a linear regression model that uses L2 regularization to prevent overfitting. The regularization term is the sum of the squares of the coefficients multiplied by the regularization parameter alpha. The objective function of ridge regression is to minimize the sum of the squared residuals and the regularization term.\n",
    "\n",
    "Formula for ridge regression: \n",
    "\n",
    "$$\\text{minimize} \\left( \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} \\beta_j^2 \\right)$$\n",
    "\n",
    "where: \n",
    "- $y_i$ is the true value of the target variable for the $i$-th observation\n",
    "- $\\hat{y}_i$ is the predicted value of the target variable for the $i$-th observation\n",
    "- $\\beta_j$ is the coefficient of the $j$-th feature\n",
    "- $n$ is the number of observations\n",
    "- $p$ is the number of features\n",
    "- $\\alpha$ is the regularization parameter\n",
    "\n",
    "Furthermore, the regularization parameter alpha controls the strength of the regularization term. A higher value of alpha results in a stronger regularization, which can help prevent overfitting. \n",
    "\n",
    "**'Regularization'** is important when the number of features is large compared to the number of observations, as this can lead to overfitting. Ridge regression is particularly useful when the features are highly correlated, as it can help stabilize the coefficients and reduce the variance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: [0.8 1.4]\n",
      "Intercept: 4.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# Ridge regression model\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# print\n",
    "print('Coefficient:', clf.coef_)\n",
    "print('Intercept:', clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Linear Regression and Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libearies and titanic dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Farhan Ali\\AppData\\Local\\Temp\\ipykernel_10096\\1042225332.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['age'] = df['age'].fillna(df['age'].mean())\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "# preprocess and model\n",
    "data = ['survived', 'pclass', 'sex', 'age', 'fare']\n",
    "df = titanic[data]\n",
    "\n",
    "# Drop missing values\n",
    "df['age'] = df['age'].fillna(df['age'].mean())\n",
    "\n",
    "# split into X and y\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.13704587957535952\n",
      "Ridge Regression MSE: 0.13706266431159014\n",
      "Linear Regression R2: 0.4214641597530838\n",
      "Ridge Regression R2: 0.42139330339820036\n",
      "Linear Regression MAE: 0.2886488550842549\n",
      "Ridge Regression MAE: 0.2890570390376864\n",
      "Linear Regression MAPE: 696608086638462.2\n",
      "Ridge Regression MAPE: 697368985288119.1\n",
      "Linear Regression RMSE: 0.3701970820729946\n",
      "Ridge Regression RMSE: 0.3702197513796234\n"
     ]
    }
   ],
   "source": [
    "# create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "categorical_featues = ['sex']\n",
    "numerical_features = ['pclass', 'age', 'fare']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [('num', 'passthrough', numerical_features),\n",
    "                                                 ('cat', OneHotEncoder(), categorical_featues)])\n",
    "\n",
    "# Linenar regression pipeline\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', LinearRegression())])\n",
    "\n",
    "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                    ('regressor', Ridge(alpha = 1.0))])\n",
    "\n",
    "# train and evaluate the model\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred = lr_pipeline.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, y_pred)\n",
    "lr_r2 = r2_score(y_test, y_pred)\n",
    "lr_mae = mean_absolute_error(y_test, y_pred)\n",
    "lr_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "y_pred = ridge_pipeline.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, y_pred)\n",
    "ridge_r2 = r2_score(y_test, y_pred)\n",
    "ridge_mae = mean_absolute_error(y_test, y_pred)\n",
    "ridge_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "\n",
    "print('Linear Regression MSE:', lr_mse)\n",
    "print('Ridge Regression MSE:', ridge_mse)\n",
    "\n",
    "print('Linear Regression R2:', lr_r2)\n",
    "print('Ridge Regression R2:', ridge_r2)\n",
    "\n",
    "print('Linear Regression MAE:', lr_mae)\n",
    "print('Ridge Regression MAE:', ridge_mae)\n",
    "\n",
    "print('Linear Regression MAPE:', lr_mape)\n",
    "print('Ridge Regression MAPE:', ridge_mape)\n",
    "\n",
    "print('Linear Regression RMSE:', lr_rmse)\n",
    "print('Ridge Regression RMSE:', ridge_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
